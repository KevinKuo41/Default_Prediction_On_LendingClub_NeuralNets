{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Importance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def nn2_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(42, activation='tanh', kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001))) # Input layer\n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(10, activation='tanh', kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001))) # hidden layer 1\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(11, activation='tanh', kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001))) # hidden layer 2\n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(1, activation='sigmoid'))                                                                                   # Output layer\n",
    "    model.compile(loss=BinaryCrossentropy(from_logits=False), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  metrics=[f1, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    return model\n",
    "\n",
    "\n",
    "def nn3_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(42, activation='tanh', kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001)))  # Input layer\n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(10, activation='tanh', kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001)))  # hidden layer 1\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(22, activation='tanh', kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001)))  # hidden layer 2\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(41, activation='tanh', kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001)))  # hidden layer 3\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))                                                                                    # Output layer\n",
    "    model.compile(loss=BinaryCrossentropy(from_logits=False), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  metrics=[f1, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    return model\n",
    "\n",
    "\n",
    "def nn4_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(42, activation='tanh', kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001)))  # Input layer\n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(22, activation='tanh', kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001)))  # hidden layer 1\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(7, activation='tanh', kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001)))   # hidden layer 2\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(48, activation='tanh', kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001)))  # hidden layer 3\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(50, activation='tanh', kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001)))  # hidden layer 4\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))                                                                                    # Output layer\n",
    "    model.compile(loss=BinaryCrossentropy(from_logits=False), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  metrics=[f1, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X_tv, X_test, y_tv, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_tv, y_tv, test_size=0.25, random_state=random_state)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### NN2 Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13875/13875 [==============================] - 22s 2ms/step - loss: 0.5688 - f1: 0.2919 - precision: 0.5555 - recall: 0.2165\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\pythonProject1\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": "sub_grade                 0.365354\nterm                      0.161303\ngrade                     0.161055\nint_rate                  0.117531\ninstallment               0.037591\nloan_amnt                 0.037547\ntot_hi_cred_lim           0.031448\nverification_status       0.027424\nt_inq_last_6mths          0.024595\nhome_ownership            0.023568\ntotal_bc_limit            0.021527\nnum_actv_bc_tl            0.015102\ndti                       0.014362\nopen_rev_ratio            0.012209\navg_cur_bal               0.011154\nemp_length                0.005767\nt_open_il_12m             0.003630\nt_num_tl_90g_dpd_24m      0.003605\nnum_op_rev_tl             0.002553\ntotal_acc                 0.001818\nt_pub_rec_bankruptcies    0.001787\nannual_inc                0.001159\nactive_ratio_bc           0.000893\nissue_d                  -0.000085\naddr_state               -0.000164\nt_tax_liens              -0.000185\nt_pub_rec                -0.000307\nnum_accts_ever_120_pd    -0.000601\nt_delinq_2yrs            -0.001261\npurpose                  -0.002373\nearliest_cr_line         -0.003445\nnum_il_tl                -0.003672\ncoborrow                 -0.004724\nnum_rev_accts            -0.005007\ntime_until_fc            -0.005142\ntotal_bal_ex_mort        -0.005239\nnum_bc_tl                -0.005970\nrevol_util               -0.006193\npercent_bc_gt_75         -0.006266\nrevol_bal                -0.009086\nopen_acc                 -0.011023\ntot_cur_bal              -0.012239\ndtype: float64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = KerasClassifier(build_fn=nn2_model)\n",
    "my_model.fit(X_train, y_train)\n",
    "\n",
    "perm_nn2 = PermutationImportance(my_model, scoring='f1', random_state=random_state).fit(X_test, y_test)\n",
    "nn2_importances_1 = pd.Series(perm_nn2.feature_importances_, index=X.columns.tolist()).sort_values(ascending=False)\n",
    "nn2 = nn2_importances_1 /(nn2_importances_1.sum())\n",
    "nn2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### NN3 Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13875/13875 [==============================] - 24s 2ms/step - loss: 0.5723 - f1: 0.2791 - precision_1: 0.5550 - recall_1: 0.2062\n"
     ]
    },
    {
     "data": {
      "text/plain": "sub_grade                 0.369577\nint_rate                  0.145528\ngrade                     0.143020\nterm                      0.116306\ninstallment               0.045862\nloan_amnt                 0.040807\nverification_status       0.034381\ntotal_bc_limit            0.023933\ndti                       0.021000\nt_inq_last_6mths          0.018622\ntot_hi_cred_lim           0.018492\nhome_ownership            0.017359\nemp_length                0.014408\nnum_actv_bc_tl            0.013730\nopen_rev_ratio            0.013601\nnum_op_rev_tl             0.009791\nt_open_il_12m             0.007405\navg_cur_bal               0.004844\nactive_ratio_bc           0.003767\nt_pub_rec_bankruptcies    0.003494\nt_pub_rec                 0.003180\nt_num_tl_90g_dpd_24m      0.001199\ntime_until_fc             0.000044\nissue_d                  -0.000160\nrevol_util               -0.000239\nnum_accts_ever_120_pd    -0.000248\naddr_state               -0.000463\nannual_inc               -0.000814\nt_tax_liens              -0.000919\nt_delinq_2yrs            -0.000934\npurpose                  -0.001226\nnum_rev_accts            -0.001792\nearliest_cr_line         -0.001799\npercent_bc_gt_75         -0.001953\ncoborrow                 -0.002153\nnum_il_tl                -0.002683\nnum_bc_tl                -0.005712\ntotal_bal_ex_mort        -0.005761\ntotal_acc                -0.006409\nopen_acc                 -0.008330\nrevol_bal                -0.011711\ntot_cur_bal              -0.017045\ndtype: float64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = KerasClassifier(build_fn=nn3_model)\n",
    "my_model.fit(X_train, y_train)\n",
    "\n",
    "perm_nn3 = PermutationImportance(my_model, scoring='f1', random_state=random_state).fit(X_test, y_test)\n",
    "nn3_importances_1 = pd.Series(perm_nn3.feature_importances_, index=X.columns.tolist()).sort_values(ascending=False)\n",
    "nn3 = nn3_importances_1 /(nn3_importances_1.sum())\n",
    "nn3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### NN4 Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13875/13875 [==============================] - 28s 2ms/step - loss: 0.5809 - f1: 0.2420 - precision_2: 0.5441 - recall_2: 0.1724\n"
     ]
    },
    {
     "data": {
      "text/plain": "sub_grade                 0.307731\ngrade                     0.160616\nterm                      0.152170\nint_rate                  0.119157\nverification_status       0.035962\nloan_amnt                 0.032214\nhome_ownership            0.029719\ntot_hi_cred_lim           0.027407\ninstallment               0.022178\ntotal_bc_limit            0.020632\ndti                       0.019017\nt_inq_last_6mths          0.013001\ntime_until_fc             0.011394\nearliest_cr_line          0.009414\nnum_actv_bc_tl            0.008649\navg_cur_bal               0.007923\nannual_inc                0.006155\nt_open_il_12m             0.005854\nnum_op_rev_tl             0.005742\ntotal_acc                 0.004793\nopen_rev_ratio            0.004519\nemp_length                0.004195\naddr_state                0.003285\nt_pub_rec                 0.002978\ntotal_bal_ex_mort         0.002776\nt_pub_rec_bankruptcies    0.002399\nnum_il_tl                 0.002257\nt_num_tl_90g_dpd_24m      0.002128\nrevol_bal                 0.001775\nnum_accts_ever_120_pd     0.001299\nissue_d                   0.000408\nnum_rev_accts             0.000269\npercent_bc_gt_75         -0.000082\nnum_bc_tl                -0.000158\nt_delinq_2yrs            -0.000250\nt_tax_liens              -0.000764\nrevol_util               -0.000878\npurpose                  -0.001414\ncoborrow                 -0.001693\nopen_acc                 -0.006106\nactive_ratio_bc          -0.006725\ntot_cur_bal              -0.009945\ndtype: float64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = KerasClassifier(build_fn=nn4_model)\n",
    "my_model.fit(X_train, y_train)\n",
    "\n",
    "perm_nn4 = PermutationImportance(my_model, scoring='f1', random_state=random_state).fit(X_test, y_test)\n",
    "nn4_importances_1 = pd.Series(perm_nn4.feature_importances_, index=X.columns.tolist()).sort_values(ascending=False)\n",
    "nn4 = nn4_importances_1 /(nn4_importances_1.sum())\n",
    "nn4"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "machine_shape": "hm",
   "name": "Big_data_II_NN_models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
